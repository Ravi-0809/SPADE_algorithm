\section{Results}

Even though the SPADE algorithm was run only a 20\% sample of the data. The results generated are constant when tried across multiple random shuffles of the dataset. The results are shown in Table \ref{results}. These results were generated with a min\_sup of 0.05. These frequent patterns contain 13 frequent 1-sequences, 8 frequent 2-sequences, and 2 frequent 3-sequences. No joins are possible on the frequent 3 sequences hence no more sequences can be formed.

\begin{table}[htbp]
    \caption{Frequent patterns generated by SPADE}
    \label{results}
    \begin{center}
        \begin{tabular}{|c|L|}
            \hline
            \textbf{Frequent patterns} & 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13 ,14, (1,1), (1,2), (2,2), (7,7), (6,6), (4,4), (8,8), (14,14), (1,1,2), (1,2,1) \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

Different combinations of min\_sup and sampling percentage were tried out on the dataset. The results in Table \ref{results} shows the generated frequent sequences for a min\_sup of 0.05 on a 20\% sample of the dataset.

\section{Conclusion}

The SPADE algorithm was implemented successfully on the given MSNBC's anonymous web dataset. This implementation is faster and more efficient than other implementations in python available online. Although the algorithm could not be run on the entire dataset at once due to hardware constraints, the algorithm gives generates the correct results on all segments of the dataset.

The only drawback of the implementation is that this code will only work on this specific type of sequential dataset, i.e, a sequential dataset with all sequences having only one element per event.